{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a8019e7",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mouryarahul/7CS107_PracticalWorks_Assignment/blob/master/Week9_Practical_Assignment_Part1.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Week 9 Practical Assignment Part-1 (Simplified Convolutions)\n",
    "\n",
    "## Learning Objectives\n",
    "By completing this assignment, you will:\n",
    "- Implement **1D** and **2D** convolution from first principles using **NumPy** and **Python for-loops** (no high-level convolution ops).  \n",
    "- Understand **stride**, **dilation**, **channels**, and **output shape** calculations.  \n",
    "- Verify your implementations against **PyTorch** reference (\\`torch.nn.functional.conv1d/conv2d\\`).  \n",
    "> **Academic Honesty:** You may discuss ideas with peers; however, all code you submit must be your own. Cite any external resources you use.\n",
    "\n",
    "## Environment & Requirements\n",
    "- Python 3.8+\n",
    "- Packages: `numpy`, `matplotlib`, `torch`, `torchvision`, `tqdm`, `scikit-learn` (for evaluation)\n",
    "\n",
    "> If you are running on university machines or Colab, ensure the above libraries are available. For local runs, install via `pip install -U numpy matplotlib torch torchvision tqdm scikit-learn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 1 — 1D Convolution (20 Marks)\n",
    "**Your task:** Implement `conv1d_numpy(x, w, stride=1, dilation=1)` where:\n",
    "- `x` input has shape `(L_in,)`\n",
    "- `w` kernel has shape `(K,)`\n",
    "- Output has shape `(L_out,)` with  $ \\displaystyle L_{out} = \\left\\lfloor \\frac{L_{in} - d\\,(K-1) - 1}{s} + 1 \\right\\rfloor$\n",
    "\n",
    "Follow **cross-correlation** semantics (no kernel flip), to match PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ellipsis' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m x = np.arange(\u001b[32m10\u001b[39m, dtype=np.float32)\n\u001b[32m     22\u001b[39m w = np.array([\u001b[32m1.\u001b[39m, \u001b[32m0.\u001b[39m, -\u001b[32m1.\u001b[39m], dtype=np.float32)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33my:\u001b[39m\u001b[33m'\u001b[39m, \u001b[43mconv1d_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mconv1d_numpy\u001b[39m\u001b[34m(x, w, stride, dilation)\u001b[39m\n\u001b[32m     12\u001b[39m L_out = ... \u001b[38;5;66;03m# Your code goes here\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m#TODO: implement the convolution operation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m y = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Your code goes here: main loop to compute convolution\u001b[39;00m\n\u001b[32m     17\u001b[39m ...\n",
      "\u001b[31mTypeError\u001b[39m: 'ellipsis' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#TODO: complete the function implementation\n",
    "def conv1d_numpy(x: np.ndarray, w: np.ndarray, stride: int = 1, dilation: int = 1) -> np.ndarray:\n",
    "    '''Perform 1D convolution on input array x with kernel w.'''\n",
    "    \n",
    "    assert x.ndim == 1 and w.ndim == 1, \"x: (L_in,), w: (K,)\"\n",
    "    L_in = x.shape[0]\n",
    "    K = w.shape[0]\n",
    "    assert stride >= 1 and dilation >= 1\n",
    "\n",
    "    #TODO: compute output length and check if it is valid (greater than zero)\n",
    "    L_out = ... # Your code goes here\n",
    "    assert ... # Your code goes here: check if L_out is greater than zero\n",
    "    #TODO: implement the convolution operation\n",
    "    y = np.zeros((L_out,), dtype=x.dtype)\n",
    "    # Your code goes here: main loop to compute convolution\n",
    "    ...\n",
    "    return y\n",
    "\n",
    "# Quick sanity\n",
    "x = np.arange(10, dtype=np.float32)\n",
    "w = np.array([1., 0., -1.], dtype=np.float32)\n",
    "print('y:', conv1d_numpy(x, w, stride=1, dilation=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Verify vs PyTorch: `F.conv1d`\n",
    "We lift the scalar vectors to PyTorch shapes `(N=1, C=1, L)` and `(C_out=1, C_in=1, K)`.\n",
    "\n",
    "Below is the Script to Test your implemented function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: torch.Size([1, 1, 12]) NumPy: (12,) max|diff|= 4.76837158203125e-07\n",
      "✅ conv1d (scalar) matches torch.nn.functional.conv1d\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "x = torch.randn(1,1,31)\n",
    "w = torch.randn(1,1,5)\n",
    "# First test\n",
    "y_np = conv1d_numpy(x.numpy().reshape(-1), w.numpy().reshape(-1), stride=2, dilation=2)\n",
    "y_t = F.conv1d(x, w, bias=None, stride=2, dilation=2, padding=0)\n",
    "max_abs_diff = float(np.max(np.abs(y_np - y_t.numpy().reshape(-1))))\n",
    "print('Torch:', y_t.shape, 'NumPy:', y_np.shape, 'max|diff|=', max_abs_diff)\n",
    "assert max_abs_diff < 1e-6\n",
    "print('✅ conv1d (scalar) matches torch.nn.functional.conv1d')\n",
    "\n",
    "# Second test\n",
    "y_np = conv1d_numpy(x.numpy().reshape(-1), w.numpy().reshape(-1), stride=3, dilation=1)\n",
    "y_t = F.conv1d(x, w, bias=None, stride=3, dilation=1, padding=0)\n",
    "max_abs_diff = float(np.max(np.abs(y_np - y_t.numpy().reshape(-1))))\n",
    "print('Torch:', y_t.shape, 'NumPy:', y_np.shape, 'max|diff|=', max_abs_diff)\n",
    "assert max_abs_diff < 1e-6\n",
    "print('✅ conv1d (scalar) matches torch.nn.functional.conv1d')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 2 — 2D Convolution (20 Marks)\n",
    "**Your task:** Implement `conv2d_numpy(x, w, stride=(1,1), dilation=(1,1))` where:\n",
    "- `x` has shape `(H_in, W_in)`\n",
    "- `w` has shape `(K_h, K_w)`\n",
    "- Output has shape `(H_out, W_out)` with  \n",
    "  $$H_{out} = \\left\\lfloor \\frac{H_{in} - d_h\\,(K_h-1) - 1}{s_h} + 1 \\right\\rfloor$$\n",
    "  $$W_{out} = \\left\\lfloor \\frac{W_{in} - d_w\\,(K_w-1) - 1}{s_w} + 1 \\right\\rfloor$$\n",
    "\n",
    "Again, use **cross-correlation** semantics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: (3, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def _pair(v):\n",
    "    if isinstance(v, (tuple, list)):\n",
    "        assert len(v) == 2\n",
    "        return int(v[0]), int(v[1])\n",
    "    return int(v), int(v)\n",
    "\n",
    "#TODO: complete the function implementation\n",
    "def conv2d_numpy_scalar(x: np.ndarray, w: np.ndarray, stride=1, dilation=1) -> np.ndarray:\n",
    "    assert x.ndim == 2 and w.ndim == 2, \"x: (H_in,W_in), w: (K_h,K_w)\"\n",
    "    H_in, W_in = int(x.shape[0]), int(x.shape[1])\n",
    "    K_h, K_w = int(w.shape[0]), int(w.shape[1])\n",
    "    s_h, s_w = _pair(stride)\n",
    "    d_h, d_w = _pair(dilation)\n",
    "    assert s_h>=1 and s_w>=1 and d_h>=1 and d_w>=1\n",
    "\n",
    "    #TODO: compute output height and width and check if they are valid (greater than zero)\n",
    "    H_out = ... # Your code goes here\n",
    "    W_out = ... # Your code goes here \n",
    "    assert ... # Your code goes here: check if H_out and W_out are greater than zero  \n",
    "    y = np.zeros((H_out, W_out), dtype=x.dtype)\n",
    "    #TODO: implement the convolution operation: the main nested loops\n",
    "    return y\n",
    "\n",
    "# Quick sanity\n",
    "x = np.arange(7*8, dtype=np.float32).reshape(7,8)\n",
    "w = np.ones((3,3), dtype=np.float32)\n",
    "print('y shape:', conv2d_numpy_scalar(x, w, stride=(2,2), dilation=(1,1)).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Verify vs PyTorch: `F.conv2d`\n",
    "We lift the 2D arrays to shapes `(1,1,H,W)` and `(1,1,K_h,K_w)` for PyTorch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: (1, 1, 11, 25) NumPy: (11, 25) max|diff|= 1.9073486328125e-06\n",
      "✅ conv2d (scalar) matches torch.nn.functional.conv2d\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "x = torch.randn(1,1,29,31)\n",
    "w = torch.randn(1,1,5,4)\n",
    "\n",
    "# First test\n",
    "y_np = conv2d_numpy_scalar(x.numpy().reshape(x.shape[-2], x.shape[-1]),\n",
    "                           w.numpy().reshape(w.shape[-2], w.shape[-1]),\n",
    "                           stride=(2,1), dilation=(2,2))\n",
    "y_t = F.conv2d(x, w, bias=None, stride=(2,1), dilation=(2,2), padding=0)\n",
    "\n",
    "max_abs_diff = float(np.max(np.abs(y_np - y_t.numpy().reshape(y_np.shape))))\n",
    "print('Torch:', tuple(y_t.shape), 'NumPy:', y_np.shape, 'max|diff|=', max_abs_diff)\n",
    "assert max_abs_diff < 1e-5\n",
    "print('✅ conv2d (scalar) matches torch.nn.functional.conv2d')\n",
    "\n",
    "# Second test\n",
    "y_np = conv2d_numpy_scalar(x.numpy().reshape(x.shape[-2], x.shape[-1]),\n",
    "                           w.numpy().reshape(w.shape[-2], w.shape[-1]),\n",
    "                           stride=(2,2), dilation=(2,2))\n",
    "y_t = F.conv2d(x, w, bias=None, stride=(2,2), dilation=(2,2), padding=0)\n",
    "max_abs_diff = float(np.max(np.abs(y_np - y_t.numpy().reshape(y_np.shape))))\n",
    "print('Torch:', tuple(y_t.shape), 'NumPy:', y_np.shape, ' max|diff|=', max_abs_diff)\n",
    "assert max_abs_diff < 1e-5\n",
    "print('✅ conv2d (scalar) matches torch.nn.functional.conv2d')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
